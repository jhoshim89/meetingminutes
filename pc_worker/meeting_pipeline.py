"""
íšŒì˜ë¡ ìƒì„± íŒŒì´í”„ë¼ì¸
======================
ì˜¤ë””ì˜¤ â†’ ì „ì‚¬ â†’ ìš”ì•½/íšŒì˜ë¡ â†’ DOCX

ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ í•˜ë‚˜ì˜ ëª…ë ¹ìœ¼ë¡œ ì‹¤í–‰
"""

import argparse
import asyncio
import json
import sys
import time
import uuid
from pathlib import Path
from typing import Dict, Optional, Any

# ë¡œì»¬ ëª¨ë“ˆ
from whisperx_engine import WhisperXEngine, WhisperXConfig
from hybrid_summarizer import HybridSummarizer

# ì„¤ì •
DEFAULT_STT_MODEL = "large-v3-turbo"
DEFAULT_LLM_MODEL = "exaone3.5:7.8b"


def format_duration(seconds: float) -> str:
    """ì´ˆë¥¼ MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    mins = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{mins:02d}:{secs:02d}"


def run_pipeline(
    audio_path: str,
    output_dir: Optional[str] = None,
    output_format: str = "all",
    stt_model: str = DEFAULT_STT_MODEL,
    llm_model: str = DEFAULT_LLM_MODEL,
    metadata: Optional[Dict[str, Any]] = None,
    skip_stt: bool = False,
    transcript_path: Optional[str] = None,
    verbose: bool = True
) -> Dict[str, str]:
    """
    ì „ì²´ íšŒì˜ë¡ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬)
        output_format: ì¶œë ¥ í˜•ì‹ ("summary", "minutes", "docx", "all")
        stt_model: WhisperX STT ëª¨ë¸
        llm_model: Ollama LLM ëª¨ë¸
        metadata: íšŒì˜ë¡ ë©”íƒ€ë°ì´í„° (ë¶€ì„œëª…, ì¥ì†Œ ë“±)
        skip_stt: STT ê±´ë„ˆë›°ê¸° (ê¸°ì¡´ ì „ì‚¬ë³¸ ì‚¬ìš©)
        transcript_path: ê¸°ì¡´ ì „ì‚¬ë³¸ íŒŒì¼ ê²½ë¡œ (skip_stt=True ì‹œ í•„ìš”)
        verbose: ìƒì„¸ ì¶œë ¥

    Returns:
        ìƒì„±ëœ íŒŒì¼ ê²½ë¡œë“¤
    """
    start_time = time.time()
    results = {}

    # ê²½ë¡œ ì„¤ì •
    audio_file = Path(audio_path)
    if output_dir:
        out_dir = Path(output_dir)
    else:
        out_dir = audio_file.parent

    out_dir.mkdir(parents=True, exist_ok=True)
    base_name = audio_file.stem

    print("=" * 60)
    print("ğŸ¤ íšŒì˜ë¡ ìƒì„± íŒŒì´í”„ë¼ì¸")
    print("=" * 60)
    print(f"ì…ë ¥: {audio_path}")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {out_dir}")
    print(f"ì¶œë ¥ í˜•ì‹: {output_format}")
    print(f"STT ëª¨ë¸: {stt_model}")
    print(f"LLM ëª¨ë¸: {llm_model}")
    print("-" * 60)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STEP 1: STT (ìŒì„± â†’ í…ìŠ¤íŠ¸)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    transcript_text = ""

    if skip_stt and transcript_path:
        print(f"\n[1/3] STT ê±´ë„ˆë›°ê¸° - ê¸°ì¡´ ì „ì‚¬ë³¸ ì‚¬ìš©: {transcript_path}")
        with open(transcript_path, 'r', encoding='utf-8') as f:
            transcript_text = f.read()
        results['transcript'] = transcript_path
    else:
        print(f"\n[1/3] STT ì²˜ë¦¬ ì¤‘... ({stt_model})")
        stt_start = time.time()

        try:
            config = WhisperXConfig(model_size=stt_model)
            engine = WhisperXEngine(config=config)

            # Generate a unique meeting_id for this run
            meeting_id = str(uuid.uuid4())

            # transcribe is async, so we need to run it with asyncio
            segments = asyncio.run(engine.transcribe(Path(audio_path), meeting_id))

            # ì „ì‚¬ë³¸ ì €ì¥
            transcript_path = out_dir / f"{base_name}_ì „ì‚¬ë³¸.txt"
            transcript_lines = []

            for segment in segments:
                start = segment.start_time
                end = segment.end_time
                text = segment.text
                speaker = segment.speaker_label or ''

                if speaker:
                    transcript_lines.append(f"[{start:.1f}s-{end:.1f}s] {speaker}: {text}")
                else:
                    transcript_lines.append(f"[{start:.1f}s-{end:.1f}s] {text}")

            transcript_text = '\n'.join(transcript_lines)

            with open(str(transcript_path), 'w', encoding='utf-8') as f:
                f.write(transcript_text)

            results['transcript'] = str(transcript_path)

            stt_duration = time.time() - stt_start
            print(f"    âœ“ ì™„ë£Œ ({stt_duration:.1f}ì´ˆ)")
            print(f"    â†’ {transcript_path}")

        except Exception as e:
            print(f"    âœ— STT ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return results

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STEP 2: LLM í•˜ì´ë¸Œë¦¬ë“œ ìš”ì•½ (êµ¬ì¡°í™” + ë¹„êµ¬ì¡°í™” í†µí•©)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    print(f"\n[2/3] LLM í•˜ì´ë¸Œë¦¬ë“œ ìš”ì•½ ì²˜ë¦¬ ì¤‘... ({llm_model})")
    summary_start = time.time()

    try:
        summarizer = HybridSummarizer(model=llm_model)

        # í•˜ì´ë¸Œë¦¬ë“œ ìš”ì•½ ì‹¤í–‰ (í•œ ë²ˆì— ëª¨ë“  í˜•ì‹ ìƒì„±)
        summary_result = summarizer.summarize(transcript_text, verbose=verbose)

        if output_format in ["summary", "all"]:
            # í†µí•© ìš”ì•½ í…ìŠ¤íŠ¸ ì €ì¥
            summary_path = out_dir / f"{base_name}_ìš”ì•½.txt"
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(summary_result.raw_text)

            results['summary'] = str(summary_path)
            print(f"    âœ“ ìš”ì•½ ì™„ë£Œ")
            print(f"    â†’ {summary_path}")

        if output_format in ["minutes", "docx", "all"]:
            # íšŒì˜ë¡ JSON ìƒì„±
            minutes_json = summarizer.to_minutes_json(
                summary_result,
                metadata=metadata or {}
            )

            json_path = out_dir / f"{base_name}_íšŒì˜ë¡.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(minutes_json, f, ensure_ascii=False, indent=2)

            results['minutes_json'] = str(json_path)
            print(f"    âœ“ íšŒì˜ë¡ JSON ì™„ë£Œ")
            print(f"    â†’ {json_path}")

        summary_duration = time.time() - summary_start
        print(f"    ì´ ìš”ì•½ ì‹œê°„: {summary_duration:.1f}ì´ˆ")

    except Exception as e:
        print(f"    âœ— ìš”ì•½ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return results

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STEP 3: DOCX ìƒì„±
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    if output_format in ["docx", "all"] and 'minutes_json' in results:
        print(f"\n[3/3] DOCX íšŒì˜ë¡ ìƒì„± ì¤‘...")
        docx_start = time.time()

        try:
            import subprocess

            script_path = Path(__file__).parent / "generate_minutes_docx.js"
            docx_path = out_dir / f"{base_name}_íšŒì˜ë¡.docx"

            result = subprocess.run(
                ["node", str(script_path), results['minutes_json'], str(docx_path)],
                capture_output=True,
                text=True,
                cwd=str(Path(__file__).parent)
            )

            if result.returncode == 0:
                results['docx'] = str(docx_path)
                docx_duration = time.time() - docx_start
                print(f"    âœ“ ì™„ë£Œ ({docx_duration:.1f}ì´ˆ)")
                print(f"    â†’ {docx_path}")
            else:
                print(f"    âœ— DOCX ìƒì„± ì˜¤ë¥˜: {result.stderr}")

        except FileNotFoundError:
            print("    âœ— Node.jsê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - JSONë§Œ ìƒì„±ë¨")
        except Exception as e:
            print(f"    âœ— DOCX ìƒì„± ì˜¤ë¥˜: {e}")
    else:
        print(f"\n[3/3] DOCX ìƒì„± ê±´ë„ˆë›°ê¸°")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì™„ë£Œ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    total_duration = time.time() - start_time
    print("\n" + "=" * 60)
    print(f"âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ (ì´ {total_duration:.1f}ì´ˆ)")
    print("=" * 60)

    if results:
        print("\nìƒì„±ëœ íŒŒì¼:")
        for key, path in results.items():
            print(f"  - {key}: {path}")

    return results


def main():
    parser = argparse.ArgumentParser(
        description="íšŒì˜ ìŒì„± â†’ ì „ì‚¬ â†’ ìš”ì•½/íšŒì˜ë¡ â†’ DOCX ìë™ ìƒì„±",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì¶œë ¥ í˜•ì‹:
  summary  - ìì—°ìŠ¤ëŸ¬ìš´ ìš”ì•½ (í´ë¡œë°”ë…¸íŠ¸ ìŠ¤íƒ€ì¼)
  minutes  - íšŒì˜ë¡ JSON
  docx     - íšŒì˜ë¡ DOCX ë¬¸ì„œ
  all      - ëª¨ë“  í˜•ì‹ (ê¸°ë³¸ê°’)

ì˜ˆì‹œ:
  # ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
  python meeting_pipeline.py ../data/íšŒì˜.m4a

  # ìš”ì•½ë§Œ ìƒì„±
  python meeting_pipeline.py ../data/íšŒì˜.m4a -f summary

  # ê¸°ì¡´ ì „ì‚¬ë³¸ìœ¼ë¡œ íšŒì˜ë¡ ìƒì„±
  python meeting_pipeline.py ../data/íšŒì˜.m4a --skip-stt -t ../data/íšŒì˜_ì „ì‚¬ë³¸.txt -f docx

  # ë©”íƒ€ë°ì´í„° ì§€ì •
  python meeting_pipeline.py ../data/íšŒì˜.m4a --department "ìˆ˜ì˜ê³¼ëŒ€í•™" --location "êµìˆ˜íšŒì˜ì‹¤"
        """
    )

    parser.add_argument('audio', help='ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('-o', '--output-dir', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('-f', '--format', default='all',
                        choices=['summary', 'minutes', 'docx', 'all'],
                        help='ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸: all)')
    parser.add_argument('--stt-model', default=DEFAULT_STT_MODEL,
                        help=f'STT ëª¨ë¸ (ê¸°ë³¸: {DEFAULT_STT_MODEL})')
    parser.add_argument('--llm-model', default=DEFAULT_LLM_MODEL,
                        help=f'LLM ëª¨ë¸ (ê¸°ë³¸: {DEFAULT_LLM_MODEL})')
    parser.add_argument('--skip-stt', action='store_true',
                        help='STT ê±´ë„ˆë›°ê¸° (ê¸°ì¡´ ì „ì‚¬ë³¸ ì‚¬ìš©)')
    parser.add_argument('-t', '--transcript', help='ê¸°ì¡´ ì „ì‚¬ë³¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('-q', '--quiet', action='store_true',
                        help='ê°„ëµí•œ ì¶œë ¥')

    # ë©”íƒ€ë°ì´í„° ì˜µì…˜
    parser.add_argument('--department', help='ë¶€ì„œëª…')
    parser.add_argument('--location', help='ì¥ì†Œ')
    parser.add_argument('--datetime', help='ì¼ì‹œ')
    parser.add_argument('--organizer', help='ì†Œì§‘ì')
    parser.add_argument('--attendees', help='ì°¸ì„ì (ì‰¼í‘œë¡œ êµ¬ë¶„)')
    parser.add_argument('--absentees', help='ë¶ˆì°¸ì')

    args = parser.parse_args()

    # ë©”íƒ€ë°ì´í„° êµ¬ì„± (Noneì´ ì•„ë‹Œ ê°’ë§Œ í¬í•¨)
    metadata_fields = ['department', 'location', 'datetime', 'organizer', 'attendees', 'absentees']
    metadata = {k: getattr(args, k) for k in metadata_fields if getattr(args, k)}

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = run_pipeline(
        audio_path=args.audio,
        output_dir=args.output_dir,
        output_format=args.format,
        stt_model=args.stt_model,
        llm_model=args.llm_model,
        metadata=metadata if metadata else None,
        skip_stt=args.skip_stt,
        transcript_path=args.transcript,
        verbose=not args.quiet
    )

    return 0 if results else 1


if __name__ == "__main__":
    sys.exit(main())
