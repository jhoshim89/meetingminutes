#!/usr/bin/env python3
"""
STT ì—”ì§„ ë¹„êµ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
WhisperX (threshold 0.4) vs í•œêµ­ì–´ íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„êµ

ì‚¬ìš©ë²•:
    python test_stt_comparison.py <audio_file.wav>
    python test_stt_comparison.py <audio_file.wav> --models all
    python test_stt_comparison.py <audio_file.wav> --models whisperx
    python test_stt_comparison.py <audio_file.wav> --models korean
"""

import asyncio
import argparse
import time
from pathlib import Path
from typing import Dict, List
import sys

# ìƒìœ„ ëª¨ë“ˆ import
sys.path.insert(0, str(Path(__file__).parent))

from models import TranscriptSegment


async def test_whisperx(audio_path: Path, meeting_id: str) -> Dict:
    """WhisperX ì—”ì§„ í…ŒìŠ¤íŠ¸ (threshold 0.4)"""
    from whisperx_engine import get_whisperx_engine, WhisperXConfig

    print("\n" + "=" * 60)
    print("ğŸ”µ í…ŒìŠ¤íŠ¸ A: WhisperX (large-v2, threshold=0.4)")
    print("=" * 60)

    config = WhisperXConfig(
        model_size="large-v2",
        language="ko",
        confidence_threshold=0.4  # í•œêµ­ì–´ ìµœì í™”
    )

    engine = get_whisperx_engine(model_size=config.model_size)
    engine.config = config

    start_time = time.time()

    try:
        await engine.initialize()
        print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {engine.get_model_info()['model_size']}")
        print(f"  - Device: {engine.config.device}")
        print(f"  - Confidence Threshold: {engine.config.confidence_threshold}")

        segments = await engine.transcribe(audio_path, meeting_id)
        elapsed = time.time() - start_time

        print(f"\nğŸ“ ì¸ì‹ ê²°ê³¼ ({len(segments)} ì„¸ê·¸ë¨¼íŠ¸):")
        print("-" * 40)

        full_text = ""
        for seg in segments:
            time_str = f"[{seg.start_time:.1f}s-{seg.end_time:.1f}s]"
            conf_str = f"(ì‹ ë¢°ë„: {seg.confidence:.2f})" if seg.confidence else ""
            print(f"  {time_str} {seg.text} {conf_str}")
            full_text += seg.text + " "

        print("-" * 40)
        print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ")

        await engine.cleanup()

        return {
            "engine": "WhisperX (large-v2, threshold=0.4)",
            "segments": segments,
            "full_text": full_text.strip(),
            "elapsed": elapsed,
            "segment_count": len(segments)
        }

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return {"engine": "WhisperX", "error": str(e)}


async def test_korean_model(audio_path: Path, meeting_id: str, model_id: str = None) -> Dict:
    """í•œêµ­ì–´ íŒŒì¸íŠœë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    from whisper_korean_engine import get_korean_whisper_engine, KoreanWhisperConfig, KOREAN_MODELS

    model_id = model_id or "ghost613/whisper-large-v3-turbo-korean"

    print("\n" + "=" * 60)
    print(f"ğŸŸ¢ í…ŒìŠ¤íŠ¸ B: í•œêµ­ì–´ íŒŒì¸íŠœë‹ ëª¨ë¸")
    print(f"   Model: {model_id}")
    print("=" * 60)

    engine = get_korean_whisper_engine(model_id=model_id)

    start_time = time.time()

    try:
        await engine.initialize()
        info = engine.get_model_info()
        print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        print(f"  - Model: {info['model_id']}")
        print(f"  - Size: {info['model_size']}")
        print(f"  - Device: {info['device']}")
        print(f"  - GPU: {info['gpu_name']}")

        segments = await engine.transcribe(audio_path, meeting_id)
        elapsed = time.time() - start_time

        print(f"\nğŸ“ ì¸ì‹ ê²°ê³¼ ({len(segments)} ì„¸ê·¸ë¨¼íŠ¸):")
        print("-" * 40)

        full_text = ""
        for seg in segments:
            time_str = f"[{seg.start_time:.1f}s-{seg.end_time:.1f}s]"
            print(f"  {time_str} {seg.text}")
            full_text += seg.text + " "

        print("-" * 40)
        print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ")

        await engine.cleanup()

        return {
            "engine": f"Korean Fine-tuned ({model_id})",
            "segments": segments,
            "full_text": full_text.strip(),
            "elapsed": elapsed,
            "segment_count": len(segments)
        }

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {"engine": f"Korean ({model_id})", "error": str(e)}


def print_comparison(results: List[Dict]):
    """ê²°ê³¼ ë¹„êµ ì¶œë ¥"""
    print("\n")
    print("=" * 70)
    print("ğŸ“Š ë¹„êµ ê²°ê³¼ ìš”ì•½")
    print("=" * 70)

    valid_results = [r for r in results if "error" not in r]

    if not valid_results:
        print("âŒ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return

    print(f"\n{'ì—”ì§„':<45} {'ì„¸ê·¸ë¨¼íŠ¸':<10} {'ì²˜ë¦¬ì‹œê°„':<10}")
    print("-" * 70)

    for r in valid_results:
        print(f"{r['engine']:<45} {r['segment_count']:<10} {r['elapsed']:.2f}ì´ˆ")

    print("\n" + "-" * 70)
    print("\nğŸ“ ì „ì²´ í…ìŠ¤íŠ¸ ë¹„êµ:")

    for r in valid_results:
        print(f"\n[{r['engine']}]")
        print(f"  {r['full_text'][:200]}..." if len(r['full_text']) > 200 else f"  {r['full_text']}")

    print("\n" + "=" * 70)
    print("ğŸ’¡ íŒ: ê²°ê³¼ë¥¼ ì§ì ‘ ë“¤ì–´ë³´ê³  ì–´ëŠ ìª½ì´ ë” ì •í™•í•œì§€ íŒë‹¨í•˜ì„¸ìš”!")
    print("=" * 70)


async def main():
    parser = argparse.ArgumentParser(description="STT ì—”ì§„ ë¹„êµ í…ŒìŠ¤íŠ¸")
    parser.add_argument("audio_file", help="í…ŒìŠ¤íŠ¸í•  ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument(
        "--models",
        choices=["all", "whisperx", "korean", "all3"],
        default="all3",
        help="í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ (ê¸°ë³¸: all3 = ì„¸ ê°œ ëª¨ë‘)"
    )

    args = parser.parse_args()

    audio_path = Path(args.audio_file)
    if not audio_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
        sys.exit(1)

    meeting_id = f"test_{int(time.time())}"
    results = []

    print("\n" + "ğŸ¤ " * 20)
    print(f"STT ì—”ì§„ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print(f"ì˜¤ë””ì˜¤ íŒŒì¼: {audio_path}")
    print("ğŸ¤ " * 20)

    # WhisperX í…ŒìŠ¤íŠ¸
    if args.models in ["all", "all3", "whisperx"]:
        result = await test_whisperx(audio_path, meeting_id)
        results.append(result)

    # í•œêµ­ì–´ ëª¨ë¸ í…ŒìŠ¤íŠ¸ - ghost613 (large-v3-turbo)
    if args.models in ["all3"]:
        result = await test_korean_model(
            audio_path, meeting_id,
            "ghost613/whisper-large-v3-turbo-korean"
        )
        results.append(result)

    # í•œêµ­ì–´ ëª¨ë¸ í…ŒìŠ¤íŠ¸ - seastar105 (medium)
    if args.models in ["all", "all3", "korean"]:
        result = await test_korean_model(
            audio_path, meeting_id,
            "seastar105/whisper-medium-ko-zeroth"
        )
        results.append(result)

    # ê²°ê³¼ ë¹„êµ
    if len(results) > 1:
        print_comparison(results)


if __name__ == "__main__":
    asyncio.run(main())
